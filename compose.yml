services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: bsllmner-mk2-app
    volumes:
      - ${PWD}:/app
      - /var/run/docker.sock:/var/run/docker.sock # For docker inspect
    environment:
      - OLLAMA_HOST=http://bsllmner-mk2-ollama:11434
    working_dir: /app
    entrypoint: [""]
    command: ["sleep", "infinity"]
    restart: unless-stopped
    init: true
    networks:
      - bsllmner-mk2-network

  ollama:
    image: ollama/ollama:0.9.0
    container_name: bsllmner-mk2-ollama
    volumes:
      - ${PWD}/ollama-data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0:11434
      - OLLAMA_KV_CACHE_TYPE=q8_0
      - OLLAMA_FLASH_ATTENTION=1
      - OLLAMA_NUM_PARALLEL=16
      - OLLAMA_MAX_QUEUE=1024
      - CUDA_VISIBLE_DEVICES=0,1
      - OLLAMA_SCHED_SPREAD=1
    entrypoint: ["/bin/ollama"]
    command: ["serve"]
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    init: true
    networks:
      - bsllmner-mk2-network

networks:
  bsllmner-mk2-network:
    name: bsllmner-mk2-network
    external: true
